import os

from logzero import logger

from ZiTokenizer.ZiTokenizer import ZiTokenizer


def get_langs():
    alphabet = ''.join(chr(x) for x in range(ord('a'), ord('z')+1))
    langs = [x+y for x in alphabet for y in alphabet]
    return langs


def test_lang(dir):
    freq_path = f"C:/data/languages/{lang}/word_frequency.tsv"
    if not os.path.exists(freq_path):
        return

    import logzero
    from logzero import logger
    logzero.logfile(os.path.join(dir, "ZiTokenizerBuild.log"), mode='w')

    tokenizer = ZiTokenizer(dir)
    # tokenizer.build(min_ratio=1.5e-6, min_freq=0)
    tokenizer.build(min_ratio=2e-6, min_freq=0)

    tokenizer = ZiTokenizer(dir)
    line = "ï¡¿'ã€‡ã¡[à¸„à¸¸à¸“à¸ˆà¸°à¸ˆà¸±à¸”à¸à¸´à¸˜à¸µà¹à¸•à¹ˆà¸‡à¸‡à¸²à¸™à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸£à¸„à¸°à¸±à¸µà¸´à¹Œà¸·à¹‡à¹à¸¶]â…§pays-g[ran]d-blanc-Ã©levÃ© Â» (ç™½é«˜å¤§å¤åœ‹)ğŸ˜€ç†‡'\x0000ğ§­"
    tokens = tokenizer.tokenize(line)
    logger.info(tokens)

    # from ZiTokenizer.glance import load_frequency
    # shuf C:/data/languages/en/word_frequency.tsv | head -n 10
    doc = os.popen(f" shuf {freq_path} -n 10").read().splitlines()
    doc = [x.split('\t') for x in doc]
    doc = [(k, int(v)) for k, v in doc]
    for k, v in doc:
        row = [k, v, tokenizer.cut(k)]
        logger.info((row))


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--lang', default="global",  type=str)
    args = parser.parse_args()

    lang = args.lang

    langs = ['aa', 'sr', 'om', 'tk', 'xh', 'zh', 'ja', 'th', 'ar', 'en', 'fr',
             'ru',   'global'][-1:]
    langs = get_langs()

    for lang in langs:
        dir = f"C:/data/languages/{lang}"
        test_lang(dir)

    """
    æ„å»ºï¼šæŒ‰ç…§é¢‘ç‡é€‰å…¥è¯æ ¹ï¼Œå…¶æ¬¡å‰ç¼€åç¼€
    åˆ‡å­—ï¼šè¯æ ¹æœ€é•¿åŒ¹é…ï¼Œå…¶æ¬¡å‰ç¼€åç¼€æœ€é•¿åŒ¹é…

"""
